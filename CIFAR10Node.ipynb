{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import torch.nn.utils as utils\n",
    "import torch.nn.utils.parametrizations as param\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torchdyn \n",
    "from torchdyn.core import NeuralODE\n",
    "\n",
    "import os\n",
    "import cv2 \n",
    "import numpy as np \n",
    "from tqdm import tqdm \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Device setup\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Step 2: Load and Normalize the CIFAR-10 Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST has 1 channel\n",
    "])\n",
    "\n",
    "\n",
    "full_train_dataset = datasets.CIFAR10(root='data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Step 3: Split the original training set into training (70%) and validation set (30%)\n",
    "train_size = int(0.7 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNODE Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNODEBlock(nn.Module):\n",
    "    def __init__(self, filters:int, kernel:int=3, expand:float=1, drop=0.3):\n",
    "        super(CNNODEBlock, self).__init__()\n",
    "        xilters = int(filters * expand)\n",
    "        self.conv1 = utils.spectral_norm(nn.Conv2d(filters, xilters, kernel - 2, padding= (kernel - 2) // 2), )\n",
    "        self.conv2 = utils.spectral_norm(nn.Conv2d(filters, xilters, kernel    , padding= kernel // 2))\n",
    "        self.conv3 = utils.spectral_norm(nn.Conv2d(filters, xilters, kernel + 2, padding= (kernel + 2) // 2))\n",
    "        self.conv =  utils.spectral_norm(nn.Conv2d(xilters*3, filters, 1))\n",
    "        self.drop = drop\n",
    "\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x3 = self.conv3(x)\n",
    "        x = torch.concat([x1, x2, x3], dim=1)\n",
    "        x = self.act(x)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UPsampling Conv Block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UPBlock(nn.Module):\n",
    "    def __init__(self, infilter:int, outfilter:int, kernel:int, moment:float, drop:float):\n",
    "        super(UPBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(infilter, outfilter, kernel, padding=kernel // 2, stride=2)\n",
    "        self.norm1 = nn.BatchNorm2d(outfilter, momentum=moment)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(outfilter, outfilter, kernel, padding=kernel // 2)\n",
    "        self.norm2 = nn.BatchNorm2d(outfilter, momentum=moment)\n",
    "\n",
    "        self.act = nn.SiLU(0.1)\n",
    "        self.drop = nn.Dropout2d(drop)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.drop(self.act(self.norm1(x)))\n",
    "        x = self.conv2(x)\n",
    "        x = self.drop(self.act(self.norm2(x)))\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, filters:int,  drop:float, classes:int):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.flat = nn.Flatten()\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.final = nn.Linear(filters, classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.drop(self.flat(self.pool(x)))\n",
    "        return F.softmax(self.final(x), dim=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNODE(nn.Module):\n",
    "    def __init__(self, num=4, filters=64, classes=10, gf=2, kernel=3, moment=0.99, drop=0.5, dropnode=0.1, dropconv=0.2):\n",
    "        super(CNNODE, self).__init__()\n",
    "        self.cnnode = nn.ModuleList([])\n",
    "        self.upsamp = nn.ModuleList([])\n",
    "        self.conv = nn.Conv2d(3, filters, 7, padding=2)\n",
    "        self.norm = nn.BatchNorm2d(filters, momentum=moment)\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        for _ in range(num):\n",
    "            f = CNNODEBlock(int(filters*gf), kernel, moment, dropnode)\n",
    "            model = NeuralODE(f, sensitivity='adjoint', solver='rk4',\n",
    "                               solver_adjoint='dopri5', atol_adjoint=1e-6, rtol_adjoint=1e-6)\n",
    "            self.cnnode.append(model)\n",
    "            self.upsamp.append(UPBlock(filters, int(filters*gf), kernel, moment, dropconv))\n",
    "            filters = int(filters*gf)\n",
    "        self.final = DenseBlock(filters, drop, classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x, t_span):\n",
    "        x = self.relu(self.norm(self.conv(x)))\n",
    "        for neuralode, neuralnetwork in zip(self.cnnode, self.upsamp):\n",
    "            x = neuralnetwork(x)\n",
    "            # t, x = neuralode(x, t_span)\n",
    "            # x = x[-1]\n",
    "            \n",
    "        return self.final(x)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n",
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n",
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n",
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/240]\n",
      "Training Loss: 1.9568, Training Accuracy: 68.43%\n",
      "Validation Loss: 1.7953, Validation Accuracy: 67.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/240]\n",
      "Training Loss: 1.8431, Training Accuracy: 77.75%\n",
      "Validation Loss: 1.7455, Validation Accuracy: 72.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/240]\n",
      "Training Loss: 1.7747, Training Accuracy: 82.72%\n",
      "Validation Loss: 1.7295, Validation Accuracy: 73.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/240]\n",
      "Training Loss: 1.7172, Training Accuracy: 86.98%\n",
      "Validation Loss: 1.7183, Validation Accuracy: 75.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/240]\n",
      "Training Loss: 1.6919, Training Accuracy: 88.48%\n",
      "Validation Loss: 1.7266, Validation Accuracy: 74.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/240]\n",
      "Training Loss: 1.6765, Training Accuracy: 89.21%\n",
      "Validation Loss: 1.7326, Validation Accuracy: 74.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/240]\n",
      "Training Loss: 1.6541, Training Accuracy: 91.08%\n",
      "Validation Loss: 1.7311, Validation Accuracy: 75.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/240]\n",
      "Training Loss: 1.6505, Training Accuracy: 91.46%\n",
      "Validation Loss: 1.7491, Validation Accuracy: 73.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/240]\n",
      "Training Loss: 1.6514, Training Accuracy: 91.29%\n",
      "Validation Loss: 1.7576, Validation Accuracy: 73.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/240]\n",
      "Training Loss: 1.6321, Training Accuracy: 92.69%\n",
      "Validation Loss: 1.7548, Validation Accuracy: 73.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [110/240]\n",
      "Training Loss: 1.6299, Training Accuracy: 92.73%\n",
      "Validation Loss: 1.7589, Validation Accuracy: 74.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [120/240]\n",
      "Training Loss: 1.6243, Training Accuracy: 93.03%\n",
      "Validation Loss: 1.7753, Validation Accuracy: 71.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [130/240]\n",
      "Training Loss: 1.6079, Training Accuracy: 94.15%\n",
      "Validation Loss: 1.7589, Validation Accuracy: 73.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [140/240]\n",
      "Training Loss: 1.6058, Training Accuracy: 94.22%\n",
      "Validation Loss: 1.7632, Validation Accuracy: 73.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [150/240]\n",
      "Training Loss: 1.6034, Training Accuracy: 94.41%\n",
      "Validation Loss: 1.7637, Validation Accuracy: 73.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [160/240]\n",
      "Training Loss: 1.5921, Training Accuracy: 95.06%\n",
      "Validation Loss: 1.7695, Validation Accuracy: 72.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [166/240]:  88%|████████▊ | 121/137 [00:18<00:02,  6.67it/s, train_accuracy=95.1, train_loss=1.59]"
     ]
    }
   ],
   "source": [
    "t_span = torch.linspace(0, 0.8, 8).to(device)\n",
    "\n",
    "model = CNNODE().to(device)  # Move the model to MPS or CPU\n",
    "# state_dict = torch.load(\"mk2_dict.pt\")  # Load the state_dict from the file\n",
    "# model.load_state_dict(state_dict)\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-Entropy loss for classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=3e-3)  # Adam optimizer\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.75)\n",
    "\n",
    "def l1_loss_on_bias(model, l1_lambda):\n",
    "    l1_loss = 0.0\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad and param.ndimension() == 1:  # Check if it's a bias (usually 1D)\n",
    "            l1_loss += torch.sum(torch.abs(param))\n",
    "    return l1_lambda * l1_loss\n",
    "\n",
    "\n",
    "# Step 5: Combined Training and Validation Loop with tqdm progress bar and accuracy updates\n",
    "def train_and_validate(model, train_loader, val_loader, optimizer, criterion, scheduler, epochs=5):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        # Training Loop with tqdm\n",
    "        loop = tqdm(train_loader, desc=f'Epoch [{epoch+1}/{epochs}]', leave=False)\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to MPS or CPU\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images, t_span)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            l1_penalty = l1_loss_on_bias(model, 5e-5)\n",
    "            loss = loss + l1_penalty\n",
    "\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate training stats\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "            # Calculate batch accuracy\n",
    "            batch_accuracy = 100 * (correct_train / total_train)\n",
    "\n",
    "            # Update tqdm progress bar with current loss and accuracy\n",
    "            loop.set_postfix(train_loss=loss.item(), train_accuracy=batch_accuracy)\n",
    "\n",
    "        # Adjust the learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        # Calculate training loss and accuracy\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "        # Validation Loop with tqdm\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            val_loop = tqdm(val_loader, desc=\"Validation\", leave=False)\n",
    "            for images, labels in val_loop:\n",
    "                images, labels = images.to(device), labels.to(device)  # Move validation data to device\n",
    "                outputs = model(images, t_span)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "                # Calculate batch accuracy\n",
    "                batch_val_accuracy = 100 * (correct_val / total_val)\n",
    "\n",
    "                # Update tqdm progress bar with current validation loss and accuracy\n",
    "                val_loop.set_postfix(val_loss=loss.item(), val_accuracy=batch_val_accuracy)\n",
    "\n",
    "        # Calculate validation loss and accuracy\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "        # Print epoch results\n",
    "        if (epoch+1)%10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}]')\n",
    "            print(f'Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%')\n",
    "            print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "# Step 6: Train and Validate the Model\n",
    "train_and_validate(model, train_loader, val_loader, optimizer, criterion, scheduler, epochs=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.7762, Test Accuracy: 71.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "def test_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        test_loop = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
    "        for images, labels in test_loop:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move test data to MPS or CPU\n",
    "            outputs = model(images, t_span)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "            # Calculate batch accuracy\n",
    "            batch_test_accuracy = 100 * (correct_test / total_test)\n",
    "\n",
    "            # Update tqdm progress bar with current test loss and accuracy\n",
    "            test_loop.set_postfix(test_loss=loss.item(), test_accuracy=batch_test_accuracy)\n",
    "\n",
    "    # Calculate test loss and accuracy\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = 100 * correct_test / total_test\n",
    "\n",
    "    # Print 0est results\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "# After training and validation, run the test evaluation\n",
    "test_model(model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(\"mk2.pt\")\n",
    "torch.save(model.state_dict(), \"mk3_dict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a580aac5ad65c26b09914c4d39579c9a7b96bf6be88d0e5d5e57a0b213e38927"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
